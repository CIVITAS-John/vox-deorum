# Vox Agents Environment Configuration
# Copy this file to .env and fill in your API keys

# Observability Configuration (optional)
# For distributed tracing and monitoring

# Langfuse Configuration (optional)
# For LLM observability and analytics
LANGFUSE_PUBLIC_KEY=pk-lf-b501869b-734a-4589-9b35-8a63cb5a0fa0
LANGFUSE_SECRET_KEY=sk-lf-e8ade320-4624-4ca9-bb3b-1213d5bb92d8
LANGFUSE_HOST=http://149.165.172.144:3000

# LLM Provider API Keys
# At least one provider is required for the agents to function
# You would need to change vox-agents configuration to use that LLM as well

# OpenAI API Key (for GPT models)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Anthropic API Key (for Claude models)
# Get from: https://console.anthropic.com/account/keys
ANTHROPIC_API_KEY=

# Mistral AI API Key (for Mistral models)
# Get from: https://console.mistral.ai/api-keys
MISTRAL_API_KEY=

# Groq API Key (for fast inference)
# Get from: https://console.groq.com/keys
GROQ_API_KEY=

# Google Generative AI API Key (for Gemini models)
# Get from: https://aistudio.google.com/apikey
GOOGLE_GENERATIVE_AI_API_KEY=

# OpenRouter API Key (for multiple model providers)
# Get from: https://openrouter.ai/keys
OPENROUTER_API_KEY=

# Local LLM Configuration (optional)
# For running models locally with Ollama
# Default: http://127.0.0.1:11434
OLLAMA_URL=http://127.0.0.1:11434